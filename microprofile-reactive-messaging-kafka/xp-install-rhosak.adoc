// Keeping this file in the reactive messaging quickstart for now (rather than ../shared-doc
// since it will be quite application specific
[[install_rhosak]]
= Install RHOSAK on Openshift

The functionality of this quickstart depends on a running instance of the
https://www.redhat.com/en/technologies/cloud-computing/openshift/openshift-streams-for-apache-kafka[Red Hat OpenShift Streams for Apache Kafka (RHOSAK)] Operator. RHOSAK is a Red Hat managed cloud service based on Apache Kafka. It runs on OpenShift but outside your OpenShift environment.

== Setting up RHOSAK
We will summarize the steps required to set up a Kafka instance in RHOSAK here. They were correct at the time of writing and inspired by the following https://developers.redhat.com/developer-sandbox/activities/connecting-to-your-managed-kafka-instance[article] explaining how to set up an instance in the Developer Sandbox for Red Hat OpenShift, which allows you to try technologies on OpenShift for free. If these steps change, the RHOSAK documentation will have the up to date instructions. Finally, the steps below assume you are using the Developer Sandbox. If you are a paying customer of RHOSAK you should adjust the steps accordingly.

*Prerequisites:*

* Create a https://developers.redhat.com/products/rhosak/getting-started[RHOSAK account] before doing the following steps:

1. From the https://developers.redhat.com/products/rhosak/getting-started[RHOSAK] console, create a Kafka instance. You need to specify a name for it Kafka instance, for example `my-quickstart-kafka`. In the rest of this text we will use `<kafka-name>` to represent `my-quickstart-kafka`. Apart from the name you can use default values for everything else. It will take a few minutes for your Kafka instance to be ready.
2. Go into the instance and create a topic called `testing`. Use the suggested defaults for everything else.
3. https://github.com/redhat-developer/app-services-cli[Download] the `rhoas` application for your OS. Make it available on your path.

## Connecting the application to Kafka

First we need to log in with `rhoas`. The login process uses the browser session for the console.
[source, shell]
----
$ rhoas login
----
Then we need to make `rhoas` use our Kafka instance
[source, shell]
----
# Substitute <kafka-name> with the name of your Kafka instance
$ rhoas context set-kafka --name <kafka-name>
----

Next we call `rhoas-generate-config` to generate the configuration to connect to Kafka. This also creates a Service Account behind the scenes. The information is contained in the rhoas.env file:
[source, shell]
----
$ rhoas generate-config --type env
$ cat rhoas.env
## Generated by rhoas cli
## Kafka Configuration
KAFKA_HOST=kabir-kafk-ca-gkal-d-cv--s-j-ka.bf2.kafka.rhcloud.com:443

## Authentication Configuration
RHOAS_CLIENT_ID=srvc-acct-XXXXXX-XXXXX-XXXXXX-XXXX-XXXXXXXX
RHOAS_CLIENT_SECRET=XXXXXX-XXXXX-XXXXXX-XXXX-XXXXXXXX
RHOAS_OAUTH_TOKEN_URL=https://identity.api.openshift.com/auth/realms/rhoas/protocol/openid-connect/token
----
As you can see, it contains the location of the Kafka server as well as the credentials to connect to it.

Next we need to set up our associated Service Account to have permissions to read from and write to topics on the Kafka instance. Substitute <RHOAS_CLIENT_ID> with the value from your local copy of the rhoas.env file:

[source, shell]
----
$ rhoas kafka acl grant-access --producer --consumer --topic all --group all -y --service-account <RHOAS_CLIENT_ID>
-- SNIP --
----

We add the secret to our OpenShift instance by running the following command:

[source, shell]
----
$ oc create secret generic rhoas --from-env-file=./rhoas.env
----
The name of the secret is inferred from the name of the file, so it becomes `rhoas`.

== Configuring your application
We need to map the created `rhoas` secret so it can be used from our application.

We will discuss Helm charts <<#xp-deploy-project-rhosak, later>>. For now, link:./helm-rhosak.yml[`helm-rhoask.yml`] maps our `rhoas` secret to a volume, and mounts that volume under `/etc/config/rhoas` in the application pod.

When building the application the link:/src/main/scripts/rhosak/s2i/initialize-server.cli[] CLI script gets run, and performs the following steps.

First it adds the secret in the `/etc/config/rhoas` directory as a config source in the MicroProfile Config subsystem:
----
echo "Adding the 'rhoas' secret volume mount as a MicroProfile Config source..."

/subsystem=microprofile-config-smallrye/config-source=rhosak-binding:add(dir={path=/etc/config/rhoas})
----

This config source will contain the values from the `rhoas.env` file we saw earlier, the important ones being `KAFKA_HOST`, `RHOAS_CLIENT_ID` and `RHOAS_CLIENT_SECRET`.

We need to map these onto what our application understands, and this is done in the second part of the CLI script:
-----
echo "Adding the MicroProfile Config entries mapping the secret values..."
/subsystem=microprofile-config-smallrye/config-source=reactive-messaging-properties:add(properties={\
mp.messaging.connector.smallrye-kafka.bootstrap.servers=${KAFKA_HOST},\
mp.messaging.connector.smallrye-kafka.security.protocol=SASL_SSL,\
mp.messaging.connector.smallrye-kafka.sasl.mechanism=PLAIN,\
mp.messaging.connector.smallrye-kafka.sasl.jaas.config="\n\
org.apache.kafka.common.security.plain.PlainLoginModule required\n\
username=\"${RHOAS_CLIENT_ID}\"\n\
password=\"${RHOAS_CLIENT_SECRET}\";"\
}, ordinal=500)
-----

This has the effect of, for example, the value `mp.messaging.connector.smallrye-kafka.bootstrap.servers` using the `${KAFKA_HOST}` value provided by the `rhoas` secret.

These properties from the MicroProfile Config subsystem have the same names as some of the ones we already defined in link:src/main/resources/META-INF/microprofile-config.properties[microprofile-config.properties]. These get merged into one overall configuration. Where the same value exists in both places the one added in the CLI script above takes precedence, so `mp.messaging.connector.smallrye-kafka.bootstrap.servers` from the values provided by CLI script will be used. This is because the CLI script uses a higher `ordinal` when adding these properties.

The CLI script will get run as part of initialising the application pod, when we pass in the environment variable `QS_USE_RHOSAK=true` when building the application as we will see later. For the bootable jar with RHOSAK combination there is a `src/main/scripts/rhoasak/bootable-jar/initialise-server.cli` script that does the same.